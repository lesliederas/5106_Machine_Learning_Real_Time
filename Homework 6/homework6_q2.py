# -*- coding: utf-8 -*-
"""Homework6_Q2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yzM1RiAd2785n1mG9Ej6_n0Tq0KNQtxU
"""

import time
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from transformers import SwinForImageClassification, AutoImageProcessor
from tqdm import tqdm

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
num_epochs = 5
batch_size = 32
learning_rate = 2e-5
image_size = 224  # Resize CIFAR images to 224x224 for Swin
num_classes = 100  # CIFAR-100

# Load processor for normalization
processor = AutoImageProcessor.from_pretrained("microsoft/swin-tiny-patch4-window7-224")
transform = transforms.Compose([
    transforms.Resize((image_size, image_size)),
    transforms.ToTensor(),
    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)
])

# CIFAR-100 dataset
train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

def load_model(model_name, pretrained=True, freeze_backbone=True):
    if pretrained:
        model = SwinForImageClassification.from_pretrained(
            model_name,
            num_labels=num_classes,
            ignore_mismatched_sizes=True
        )
    else:
        model = SwinForImageClassification.from_pretrained(
            model_name,
            num_labels=num_classes,
            ignore_mismatched_sizes=True
        )
        for param in model.parameters():
            param.requires_grad = True  # All params will be trained from scratch

    if freeze_backbone:
        for param in model.swin.parameters():
            param.requires_grad = False
    else:
        for param in model.parameters():
            param.requires_grad = True

    return model.to(device)

def train(model, optimizer, criterion):
    model.train()
    start_time = time.time()
    for epoch in range(num_epochs):
        progress = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{num_epochs}]")
        running_loss = 0
        for images, labels in progress:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images).logits
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            progress.set_postfix({'loss': loss.item()})

    epoch_time = (time.time() - start_time) / num_epochs
    return epoch_time

def test(model):
    model.eval()
    total = 0
    correct = 0
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc='Testing'):
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images).logits
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    return accuracy

def run_experiment(name, model_name, pretrained, freeze_backbone):
    print(f"\n--- Running: {name} ---")
    model = load_model(model_name, pretrained=pretrained, freeze_backbone=freeze_backbone)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)

    epoch_time = train(model, optimizer, criterion)
    accuracy = test(model)

    print(f"{name} - Avg Epoch Time: {epoch_time:.2f}s, Test Accuracy: {accuracy:.2f}%")
    return name, epoch_time, accuracy

if __name__ == '__main__':
    results = []

    results.append(run_experiment("Swin-Tiny Fine-tuned", "microsoft/swin-tiny-patch4-window7-224", pretrained=True, freeze_backbone=True))
    results.append(run_experiment("Swin-Small Fine-tuned", "microsoft/swin-small-patch4-window7-224", pretrained=True, freeze_backbone=True))
    results.append(run_experiment("Swin-Tiny from Scratch", "microsoft/swin-tiny-patch4-window7-224", pretrained=True, freeze_backbone=False))
    results.append(run_experiment("Swin-Small from Scratch", "microsoft/swin-small-patch4-window7-224", pretrained=True, freeze_backbone=False))

    print("\n--- Summary ---")
    print(f"{'Model':30s} | {'Epoch Time (s)':>15s} | {'Test Accuracy (%)':>17s}")
    print("-" * 70)
    for name, t, acc in results:
        print(f"{name:30s} | {t:15.2f} | {acc:17.2f}")